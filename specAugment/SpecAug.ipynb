{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"notebook2script.py\", line 3, in <module>\n",
      "    import json,fire,re\n",
      "ModuleNotFoundError: No module named 'fire'\n"
     ]
    }
   ],
   "source": [
    "#Export\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "os.system(\"python notebook2script.py SparseImageWarp.ipynb\")\n",
    "from exp.nb_SparseImageWarp import sparse_image_warp\n",
    "from torchaudio import transforms\n",
    "from python_speech_features import logfbank, fbank\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个作者给的特征提取的代码\n",
    "class SpectrogramToDB(object):\n",
    "    \"\"\"Turns a spectrogram from the power/amplitude scale to the decibel scale.\n",
    "    This output depends on the maximum value in the input spectrogram, and so\n",
    "    may return different values for an audio clip split into snippets vs. a\n",
    "    a full clip. This method is sourced from an earlier release of torchaudio and\n",
    "    is no longer present in current versions.\n",
    "    Args:\n",
    "        stype (str): scale of input spectrogram (\"power\" or \"magnitude\").  The\n",
    "            power being the elementwise square of the magnitude. default: \"power\"\n",
    "        top_db (float, optional): minimum negative cut-off in decibels.  A reasonable number\n",
    "            is 80.\n",
    "    \"\"\"\n",
    "    def __init__(self, stype=\"power\", top_db=None):\n",
    "        self.stype = stype\n",
    "        if top_db is not None and top_db < 0:\n",
    "            raise ValueError('top_db must be positive value')\n",
    "        self.top_db = top_db\n",
    "        self.multiplier = 10. if stype == \"power\" else 20.\n",
    "        self.amin = 1e-10\n",
    "        self.ref_value = 1.\n",
    "        self.db_multiplier = np.log10(np.maximum(self.amin, self.ref_value))\n",
    "\n",
    "    def __call__(self, spec):\n",
    "        # numerically stable implementation from librosa\n",
    "        # https://librosa.github.io/librosa/_modules/librosa/core/spectrum.html\n",
    "        spec_db = self.multiplier * torch.log10(torch.clamp(spec, min=self.amin))\n",
    "        spec_db -= self.multiplier * self.db_multiplier\n",
    "\n",
    "        if self.top_db is not None:\n",
    "            spec_db = torch.max(spec_db, spec_db.new_full((1,), spec_db.max() - self.top_db))\n",
    "        return spec_db\n",
    "\n",
    "# audio是第一个参数，需要用IPYthon来读取这个音频\n",
    "def tfm_spectro(ad, sr=16000, to_db_scale=False, n_fft=1024, \n",
    "                ws=None, hop=None, f_min=0.0, f_max=-80, pad=0, n_mels=128):\n",
    "    # We must reshape signal for torchaudio to generate the spectrogram.\n",
    "    mel = transforms.MelSpectrogram(sample_rate=ad.sr, n_mels=n_mels, n_fft=n_fft, win_length=ws, hop_length=hop, \n",
    "                                    f_min=f_min, f_max=f_max, pad=pad,)(ad.sig.reshape(1, -1))\n",
    "    if to_db_scale: mel = SpectrogramToDB(stype='magnitude', top_db=f_max)(mel)\n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把张量打印出来\n",
    "def tensor_to_img(spectrogram):\n",
    "    plt.figure(figsize=(14,1)) # arbitrary, looks good on my screen.\n",
    "    plt.imshow(spectrogram[0])\n",
    "    plt.show()\n",
    "    display(spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "def time_warp(spec, W=50):\n",
    "    num_rows = spec.shape[2]\n",
    "    spec_len = spec.shape[1]\n",
    "    device = spec.device\n",
    "\n",
    "    # adapted from https://github.com/DemisEom/SpecAugment/\n",
    "    pt = (num_rows - 2* W) * torch.rand([1], dtype=torch.float) + W # random point along the time axis\n",
    "    src_ctr_pt_freq = torch.arange(0, spec_len // 2)  # control points on freq-axis\n",
    "    src_ctr_pt_time = torch.ones_like(src_ctr_pt_freq) * pt  # control points on time-axis\n",
    "    src_ctr_pts = torch.stack((src_ctr_pt_freq, src_ctr_pt_time), dim=-1)\n",
    "    src_ctr_pts = src_ctr_pts.float().to(device)\n",
    "\n",
    "    # Destination\n",
    "    w = 2 * W * torch.rand([1], dtype=torch.float) - W# distance\n",
    "    dest_ctr_pt_freq = src_ctr_pt_freq\n",
    "    dest_ctr_pt_time = src_ctr_pt_time + w\n",
    "    dest_ctr_pts = torch.stack((dest_ctr_pt_freq, dest_ctr_pt_time), dim=-1)\n",
    "    dest_ctr_pts = dest_ctr_pts.float().to(device)\n",
    "\n",
    "    # warp\n",
    "    source_control_point_locations = torch.unsqueeze(src_ctr_pts, 0)  # (1, v//2, 2)\n",
    "    dest_control_point_locations = torch.unsqueeze(dest_ctr_pts, 0)  # (1, v//2, 2)\n",
    "    warped_spectro, dense_flows = sparse_image_warp(spec, source_control_point_locations, dest_control_point_locations)\n",
    "    return warped_spectro.squeeze(3)\n",
    "\n",
    "def test_time_warp():\n",
    "    tensor_to_img(time_warp(spectro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_mask(spec, F=70, num_masks=2, replace_with_zero=False):\n",
    "    cloned = spec.clone()\n",
    "    num_mel_channels = cloned.shape[1]\n",
    "    \n",
    "    for i in range(0, num_masks):        \n",
    "        f = random.randrange(0, F)\n",
    "        f_zero = random.randrange(0, num_mel_channels - f)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (f_zero == f_zero + f): return cloned\n",
    "\n",
    "        mask_end = random.randrange(f_zero, f_zero + f) \n",
    "        if (replace_with_zero): cloned[0][f_zero:mask_end] = 0\n",
    "        else: cloned[0][f_zero:mask_end] = cloned.mean()\n",
    "    \n",
    "    return cloned\n",
    "\n",
    "def test_freq_mask():\n",
    "    tensor_to_img(freq_mask(spectro))\n",
    "    # Two Masks...\n",
    "    tensor_to_img(freq_mask(spectro, num_masks=2))\n",
    "    # with zeros\n",
    "    tensor_to_img(freq_mask(spectro, num_masks=2, replace_with_zero=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "def time_mask(spec, T=40, num_masks=2, replace_with_zero=False):\n",
    "    cloned = spec.clone()\n",
    "    len_spectro = cloned.shape[2]\n",
    "    \n",
    "    for i in range(0, num_masks):\n",
    "        t = random.randrange(0, T)\n",
    "        t_zero = random.randrange(0, len_spectro - t)\n",
    "\n",
    "        # avoids randrange error if values are equal and range is empty\n",
    "        if (t_zero == t_zero + t): return cloned\n",
    "\n",
    "        mask_end = random.randrange(t_zero, t_zero + t)\n",
    "        if (replace_with_zero): cloned[0][:,t_zero:mask_end] = 0\n",
    "        else: cloned[0][:,t_zero:mask_end] = cloned.mean()\n",
    "    return cloned\n",
    "\n",
    "def test_time_mask():\n",
    "    tensor_to_img(time_mask(spectro))\n",
    "    # Two Masks...\n",
    "    tensor_to_img(time_mask(spectro, num_masks=2))\n",
    "    # with zeros\n",
    "    tensor_to_img(time_mask(spectro, num_masks=2, replace_with_zero=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADYAAABZCAYAAAB159dSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEDklEQVR4nO2bzWtcVRjGf89kEkuDsQ0NRfxAC3HRZQ2NigslUKsgdVVcGUQIiP4B3RXqxrULhS6KFaQigthFoMRuXAnWhV/Q0CgVI2qVSC0UaZs8Lu6JXCe5zsyZmZszl/vAcO+cue+c85v33Pfe+553ZJsqqrHTAxiUarBhUw02bKrB+iVJRyUtS1qRdGJgHdku7QWMAN8DB4Ax4Cvg4CD6Kttjh4EV2z/YvgV8ABwbREdlg90H/JR7vxra/pWkBUmXJF1qqukJTXpCk5b0ezcdJRc8bJ+2PWN7ZjcTzGqOWc0B/NjN95QN9jPwQO79/aGt7yob7AtgWtLDksaAF4HzhUcrvqNmvGn3sn1H0uvABbIIecb2d8UW8WSlggHYXgQWB91PcsGjX0oaTI344SUN5o2NaNukweghbZE2mOKjYtpgVNRjQtFeSxrMGDVHo2yTBgPhO7ejLBMHi1cNthOShEZGomyTBqv2BVpxQ0wazDa+fSvKNmkwVfaWanS0mnceRF6cIXUwiI6MbcEknZF0TdK3ubZJSUuSroTt3tAuSW+FvPzXkg7lbObD8VckzXc0ugGfY+8CR1vaTgAXbU8DF8N7gGeB6fBaAN7JxqdJ4CQwS5bmPrn5Y/yfvL7ewfC2V1sw258Bay3Nx4CzYf8s8EKu/T1n+hzYI+le4Blgyfaa7T+BJbb+WFukHUi/7bf9S9j/Fdgf9oty821z9puStEDmbXZpPHJ4fQgeztaH+lZTkc/dj3FX6eH+tzDFCNtrob0oNx+Vs7c9uKhYoPPAZmSbBz7Jtb8UouNjwPUwZS8ARyTtDUHjSGgbmNqeY5LOAU8B+yStkkW3N4EPJb1CtrxzPBy+CDwHrAA3gZcBbK9JeoNsUQLglO3WgLRN592gtJimXHJ0T3PKh/002Hzqj760PdOpbemLEt0oywSXe46Vo+o+aMabJg0mNar52NJLYEs6eNDDTU3SHqvsOQZCzbhJlTSYpOhnsqTBaMRngtMOHusbWBX0mKH0x5bklTaYXc07D0Q9FVuVNlgPz8Bpg/WgGmxHVNX1MTXiwZLOUkm6ASwD+4Bx21Od2ibtMWA5pNz+6AYK0geLVg22Qzrdsu1YSQePXpS6x6JVWbDkUgOSrgI3gN1ky7mrwPvAE8BDwFXgeFjLLlSqHpsL24Ph9SrwzTZVCoVKFewQ//1noIC/w2f5KoVCpQhm4G3g0VBBANm0nAj7+SqFQiV3jgFPAo+TeeU1SZfzH9q2pLbXqOQ8ZnuzymAK+Jiskucm8BdsqVIoVFJgksYl3U22CP8I8DxwmWx67gqH5asUir8rpTsPSQfIvASwBxgHrgPnyKbng4QqhXZVB0mB9VNJTcV+qgYbNtVgw6YabNj0D9swy361h7ACAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1008x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1, 1990, 80)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADYAAABZCAYAAAB159dSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADb0lEQVR4nO2bwYtVVRzHP9+cTGbooYMiokYJ48KlDU2GC2HANAhdSauGCAYi/wB3Qm1at1BwIRmEIYHoYkBGN64CdWEpODiF0URlMWGCRATfFue8uo1d3szr3uc50/nA5d573r333M895/3e45zflW1WI0896RtoiyKWG0UsN4pYU0g6IGlO0rykY61VZHtgC7AG+ArYAawFbgK72qhr0C32EjBv+2vbvwOfAofaqGjQYluBbyv7C7HsLyRNS7ou6fqQhtzRqDsataSfVlJRcsHD9inb47bHh+kwoUkmNAnwzUquM2ix74Dtlf1tsaxxBi12DRiT9IKktcAbwMU2Khpq46J12P5D0lHgEiFCnrZ9u426BioGYHsGmGm7nuSCR1MUsdwoYrlRxHKjiOVGEcuNIpYbRSw3ilhuFLHc6Ckm6bSk+5JuVcpGJc1KuhvXG2K5JH0Yx+W/kLS7cs5UPP6upKl2dP5mOS32EXBgSdkx4IrtMeBK3Ac4CIzFZRo4CeFBAMeBCcIw9/Huw2iLnmK2rwKLS4oPAWfi9hngcKX8Ywc+B9ZL2gK8CszaXrT9CzDL4w+rUfodftts+/u4/QOwOW7Xjc33HLPvImma0NqsY7jP22sgeDjMDzWWU1Edu3+aZ/q+Tr9iP8YuRlzfj+V1Y/MDG7Pv0q/YRaAb2aaAC5XyN2N0fBl4ELvsJWC/pA0xaOyPZa3R8zsm6SywD9goaYEQ3T4Azkl6mzC9cyQePgO8BswDj4C3AGwvSnqfMCkB8J7tpQGpUZRyylFHo45zY1z2Zzdsjy/33P/vP49cKWK5UcRyo4jlRhHLjSKWG0UsN4pYbhSx3ChiubFqxZIepZL0EJgDNgIjtjct99zUW2wuDrn9vBIpSF+sb4rYE+LUkvWySTp4/BdSb7G+WbViA39ToheS7gEPgWHCdO4C8AnwCvA8cA84Eueya0m1xSbjeldc3gG+/JcshVpSFdvNP98MFPBb/KyapVBLimIGTgAvxgwCCN2yE7erWQq1JPcdA/YCewit8q6kO9UPbVtSz9+o5FrMdjfLYBNwnpDJ8wj4FR7LUqglKTFJI5KeJUzC7wReB+4Quue6eFg1S6H+Win985C0g9BKAOuBEeABcJbQPZ8jZin0yjpISqxJkuqKTVLEcqOI5UYRy40/AXA9jnGTeMm1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1008x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1990, 80])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 接入到conformer里面来\n",
    "import scipy.io.wavfile as wav\n",
    "(rate, signal) = wav.read('/root/autodl-tmp/HLT/SpecAugment/party-crowd.wav')\n",
    "fbank_feats,_= fbank(signal, rate, nfilt=80, winlen=0.005, winstep=0.005)\n",
    "fbank_feats = np.array(torch.unsqueeze(torch.tensor(fbank_feats), 0))\n",
    "print(type(fbank_feats))\n",
    "combined = time_mask(freq_mask(time_warp(torch.tensor(fbank_feats)), num_masks=2), num_masks=2)\n",
    "tensor_to_img(fbank_feats)\n",
    "tensor_to_img(combined)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
